{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a7194-5c96-4242-b0c3-bafa16a3848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from typing import List\n",
    "from IPython.display import FileLink\n",
    "import uuid\n",
    "\n",
    "# --- Setup basic logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc2fe2-1de8-4373-83eb-04d0d0151bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort_key(s: str) -> int:\n",
    "    \"\"\"A helper function to allow for natural sorting of column names like 'Class 10' after 'Class 2'.\"\"\"\n",
    "    match = re.search(r'Class (\\d+)', s)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "def create_download_link(filename: str, text: str = \"Download the merged file!\") -> HTML:\n",
    "    \"\"\"\n",
    "    Generates a more robust link to download a file from the Jupyter server.\n",
    "    This version uses a unique ID to prevent conflicts if run multiple times.\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode()\n",
    "\n",
    "    # Generate a unique ID for the link\n",
    "    link_id = f\"download-link-{uuid.uuid4()}\"\n",
    "\n",
    "    return HTML(f\"\"\"\n",
    "        <a id=\"{link_id}\" download=\"{filename}\" href=\"data:text/csv;base64,{encoded}\">\n",
    "            {text}\n",
    "        </a>\n",
    "        <script>\n",
    "            // Use a timeout to ensure the link is rendered before clicking\n",
    "            setTimeout(function() {{\n",
    "                document.getElementById('{link_id}').click();\n",
    "            }}, 100);\n",
    "        </script>\n",
    "    \"\"\")\n",
    "\n",
    "def cleanup_source_files(files_to_keep: List[str] = None):\n",
    "    \"\"\"\n",
    "    Deletes all .csv files in the current directory except for those\n",
    "    in the provided keep list. This is a destructive action.\n",
    "    \"\"\"\n",
    "    if files_to_keep is None:\n",
    "        files_to_keep = []\n",
    "        \n",
    "    logging.warning(\"--- Starting CSV file cleanup ---\")\n",
    "    deleted_count = 0\n",
    "    for p in Path.cwd().glob('*.csv'):\n",
    "        if p.is_file() and p.name not in files_to_keep:\n",
    "            try:\n",
    "                p.unlink()\n",
    "                logging.info(f\"  - üóëÔ∏è Deleted source file: {p.name}\")\n",
    "                deleted_count += 1\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Could not delete {p.name}: {e}\")\n",
    "    logging.warning(f\"--- Cleanup complete. Deleted {deleted_count} CSV file(s). ---\")\n",
    "\n",
    "\n",
    "def run_final_grade_update():\n",
    "    \"\"\"\n",
    "    Finds and merges all Canvas and iClicker files, preserving official bCourses\n",
    "    column names and sorting them naturally before calculating the final total.\n",
    "    \"\"\"\n",
    "    # Clean up previous runs\n",
    "    for p in Path.cwd().glob('updated_*'):\n",
    "        if p.is_file(): p.unlink()\n",
    "\n",
    "    # --- 1. File Discovery (Using pathlib) ---\n",
    "    try:\n",
    "        current_dir = Path.cwd()\n",
    "        bc_filenames = sorted([f.name for f in current_dir.glob('*_Grades-ENGIN_7.csv')], reverse=True)\n",
    "        ic_filenames = sorted([f.name for f in current_dir.glob('iClicker_GradesExport_Canvas_*.csv')])\n",
    "\n",
    "        if not bc_filenames:\n",
    "            raise StopIteration(\"No Canvas gradebook files found matching the pattern.\")\n",
    "\n",
    "        logging.info(f\"‚úÖ Found {len(bc_filenames)} Canvas gradebooks and {len(ic_filenames)} iClicker files.\")\n",
    "        \n",
    "    except StopIteration as e:\n",
    "        logging.error(f\"‚ùå Critical: Could not find required CSV files. {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Build a Master Map of Official Column Names ---\n",
    "    poll_column_map = {}\n",
    "    for filename in bc_filenames:\n",
    "        try:\n",
    "            df = pd.read_csv(filename, dtype=str, nrows=0) # Read only headers for efficiency\n",
    "            for col in df.columns:\n",
    "                match = re.match(r'(Class \\d+ - Poll)( \\(\\d+\\))', col)\n",
    "                if match:\n",
    "                    simple_name = match.group(1)\n",
    "                    poll_column_map[simple_name] = col # Map 'Class 1 - Poll' -> 'Class 1 - Poll (12345)'\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not read headers from {filename}: {e}\")\n",
    "    logging.info(f\"Built a map of {len(poll_column_map)} official poll column names.\")\n",
    "    \n",
    "    # --- 3. Load and Prepare a Master Gradebook ---\n",
    "    try:\n",
    "        master_bc_filename = bc_filenames[0]\n",
    "        master_df = pd.read_csv(master_bc_filename, dtype=str)\n",
    "\n",
    "        master_total_col = next((col for col in master_df.columns if re.match(r'iClicker \\(Total\\) \\(\\d+\\)', col)), None)\n",
    "        if not master_total_col:\n",
    "            logging.error(\"‚ùå Critical: Could not find the 'iClicker (Total) (number)' column.\")\n",
    "            return\n",
    "\n",
    "        is_student = pd.to_numeric(master_df['SIS User ID'], errors='coerce').notna()\n",
    "        student_data = master_df[is_student].copy()\n",
    "        special_rows = master_df[~is_student].copy()\n",
    "        \n",
    "        is_test_student = student_data['Student'] == 'Student, Test'\n",
    "        test_student_row = student_data[is_test_student].copy()\n",
    "        student_data = student_data[~is_test_student].copy()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred loading the main gradebook: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 4. Consolidate ALL Source Files into the Master Record ---\n",
    "    all_source_files = bc_filenames + ic_filenames\n",
    "    processed_poll_columns = set()\n",
    "    iclicker_poll_columns = set() \n",
    "    for filename in all_source_files:\n",
    "        try:\n",
    "            source_df = pd.read_csv(filename, dtype=str)\n",
    "            source_students = source_df[pd.to_numeric(source_df['SIS User ID'], errors='coerce').notna()].copy()\n",
    "            \n",
    "            source_poll_col_name = next((col for col in source_students.columns if 'Class' in col and 'Poll' in col), None)\n",
    "            if not source_poll_col_name: continue\n",
    "\n",
    "            simple_poll_name = re.match(r'Class \\d+ - Poll', source_poll_col_name).group(0)\n",
    "            master_poll_col_name = poll_column_map.get(simple_poll_name, simple_poll_name)\n",
    "            processed_poll_columns.add(master_poll_col_name)\n",
    "\n",
    "            if filename in ic_filenames:\n",
    "                iclicker_poll_columns.add(master_poll_col_name)\n",
    "\n",
    "            if master_poll_col_name not in student_data.columns:\n",
    "                student_data[master_poll_col_name] = 0.0\n",
    "\n",
    "            source_subset = source_students[['SIS User ID', source_poll_col_name]].rename(columns={source_poll_col_name: 'New_Score'})\n",
    "            student_data = pd.merge(student_data, source_subset, on='SIS User ID', how='left')\n",
    "            \n",
    "            # Combine scores, taking the max between existing and new\n",
    "            student_data[master_poll_col_name] = pd.to_numeric(student_data[master_poll_col_name], errors='coerce').fillna(0)\n",
    "            student_data['New_Score'] = pd.to_numeric(student_data['New_Score'], errors='coerce').fillna(0)\n",
    "            student_data[master_poll_col_name] = student_data[[master_poll_col_name, 'New_Score']].max(axis=1)\n",
    "            \n",
    "            student_data.drop(columns=['New_Score'], inplace=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"  - ‚ùå An error occurred while processing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # --- 5. Final Calculation and Reconstruction ---\n",
    "    sorted_poll_columns = sorted(list(processed_poll_columns), key=natural_sort_key)\n",
    "    logging.info(f\"Final poll columns in order: {sorted_poll_columns}\")\n",
    "\n",
    "    logging.info(f\"üîÑ Adding scores from iClicker files to '{master_total_col}'...\")\n",
    "    \n",
    "    # Ensure the existing total and new poll columns are numeric before calculation\n",
    "    student_data[master_total_col] = pd.to_numeric(student_data[master_total_col], errors='coerce').fillna(0)\n",
    "    for col in iclicker_poll_columns:\n",
    "        if col in student_data.columns:\n",
    "            student_data[col] = pd.to_numeric(student_data[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    sorted_iclicker_cols = sorted(list(iclicker_poll_columns), key=natural_sort_key)\n",
    "    \n",
    "    if sorted_iclicker_cols:\n",
    "        logging.info(f\"Columns from iClicker files to be added: {sorted_iclicker_cols}\")\n",
    "        new_iclicker_sum = student_data[sorted_iclicker_cols].sum(axis=1)\n",
    "        # Add the sum of the new scores to the existing total\n",
    "        student_data[master_total_col] += new_iclicker_sum\n",
    "    else:\n",
    "        logging.info(\"No new iClicker columns found to add. Existing total preserved.\")\n",
    "\n",
    "    # Round the final calculated total\n",
    "    student_data[master_total_col] = student_data[master_total_col].round(2)\n",
    "    \n",
    "    # Recombine the DataFrame parts\n",
    "    final_df = pd.concat([special_rows, student_data, test_student_row], ignore_index=True)\n",
    "\n",
    "    # --- 6. Save Final Truncated File ---\n",
    "    cols_to_keep = list(master_df.columns[:5]) + sorted_poll_columns + [master_total_col]\n",
    "    cols_to_keep = [col for col in cols_to_keep if col in final_df.columns]\n",
    "    \n",
    "    final_df_truncated = final_df[cols_to_keep].copy()\n",
    "\n",
    "    # Move test student to the end dynamically\n",
    "    is_test = final_df_truncated['Student'] == 'Student, Test'\n",
    "    if is_test.any():\n",
    "        test_row_data = final_df_truncated[is_test]\n",
    "        final_df_truncated = final_df_truncated[~is_test]\n",
    "        final_df_truncated = pd.concat([final_df_truncated, test_row_data], ignore_index=True)\n",
    "\n",
    "    # Set first row to be empty\n",
    "    if not final_df_truncated.empty:\n",
    "        final_df_truncated.iloc[0] = \"\"\n",
    "    \n",
    "    output_filename = f'updated_{master_bc_filename}'\n",
    "    final_df_truncated.to_csv(output_filename, encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    logging.info(f\"\\n‚ú® Done! All files consolidated. Final gradebook saved to '{output_filename}'.\")\n",
    "\n",
    "    # --- 7. Force download of the output file ---\n",
    "    display(create_download_link(output_filename))\n",
    "    \n",
    "    # --- 8. Clean up source files (optional) ---\n",
    "    cleanup_source_files(files_to_keep=[])\n",
    "\n",
    "# --- Main execution block ---\n",
    "# To run the script, call this function in a new cell:\n",
    "run_final_grade_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b9882-9d05-42db-8925-1904d2e3070e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
